% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bijectors.R
\name{tfb_sinh_arcsinh}
\alias{tfb_sinh_arcsinh}
\title{Computes\code{Y = g(X) = Sinh( (Arcsinh(X) + skewness) * tailweight )}}
\usage{
tfb_sinh_arcsinh(skewness = NULL, tailweight = NULL,
  validate_args = FALSE, name = "SinhArcsinh")
}
\arguments{
\item{skewness}{Skewness parameter.  Float-type Tensor.  Default is 0 of type float32.}

\item{tailweight}{Tailweight parameter.  Positive Tensor of same dtype as skewness and broadcastable shape.  Default is 1 of type float32.}

\item{validate_args}{Logical, default FALSE. Whether to validate input with asserts. If validate_args is
FALSE, and the inputs are invalid, correct behavior is not guaranteed.}

\item{name}{name prefixed to Ops created by this class.}
}
\value{
a bijector instance.
}
\description{
For skewness in \code{(-inf, inf)} and tailweight in \code{(0, inf)}, this
transformation is a diffeomorphism of the real line \code{(-inf, inf)}.
The inverse transform is \code{X = g^{-1}(Y) = Sinh( ArcSinh(Y) / tailweight - skewness )}.
The SinhArcsinh transformation of the Normal is described in
\href{https://oro.open.ac.uk/22510/}{Sinh-arcsinh distributions}
}
\details{
This Bijector allows a similar transformation of any distribution supported on \code{(-inf, inf)}.Meaning of the parameters
\itemize{
\item If skewness = 0 and tailweight = 1, this transform is the identity.
\item Positive (negative) skewness leads to positive (negative) skew.
\item positive skew means, for unimodal X centered at zero, the mode of Y is "tilted" to the right.
\item positive skew means positive values of Y become more likely, and negative values become less likely.
\item Larger (smaller) tailweight leads to fatter (thinner) tails.
\item Fatter tails mean larger values of |Y| become more likely.
\item If X is a unit Normal, tailweight < 1 leads to a distribution that is "flat" around Y = 0, and a very steep drop-off in the tails.
\item If X is a unit Normal, tailweight > 1 leads to a distribution more peaked at the mode with heavier tails.
To see the argument about the tails, note that for |X| >> 1 and |X| >> (|skewness| * tailweight)\strong{tailweight, we have
Y approx 0.5 X}tailweight e**(sign(X) skewness * tailweight).
}
}
\seealso{
For usage examples see \code{\link[=tfb_forward]{tfb_forward()}}, \code{\link[=tfb_inverse]{tfb_inverse()}}, \code{\link[=tfb_inverse_log_det_jacobian]{tfb_inverse_log_det_jacobian()}}.

Other bijectors: \code{\link{tfb_absolute_value}},
  \code{\link{tfb_affine_linear_operator}},
  \code{\link{tfb_affine_scalar}},
  \code{\link{tfb_affine}},
  \code{\link{tfb_batch_normalization}},
  \code{\link{tfb_blockwise}}, \code{\link{tfb_chain}},
  \code{\link{tfb_cholesky_outer_product}},
  \code{\link{tfb_cholesky_to_inv_cholesky}},
  \code{\link{tfb_correlation_cholesky}},
  \code{\link{tfb_discrete_cosine_transform}},
  \code{\link{tfb_expm1}}, \code{\link{tfb_exp}},
  \code{\link{tfb_fill_triangular}},
  \code{\link{tfb_gumbel}}, \code{\link{tfb_identity}},
  \code{\link{tfb_inline}}, \code{\link{tfb_invert}},
  \code{\link{tfb_kumaraswamy}},
  \code{\link{tfb_masked_autoregressive_default_template}},
  \code{\link{tfb_masked_autoregressive_flow}},
  \code{\link{tfb_masked_dense}},
  \code{\link{tfb_matrix_inverse_tri_l}},
  \code{\link{tfb_matvec_lu}},
  \code{\link{tfb_normal_cdf}}, \code{\link{tfb_ordered}},
  \code{\link{tfb_permute}},
  \code{\link{tfb_power_transform}},
  \code{\link{tfb_real_nvp_default_template}},
  \code{\link{tfb_real_nvp}}, \code{\link{tfb_reciprocal}},
  \code{\link{tfb_reshape}}, \code{\link{tfb_scale_tri_l}},
  \code{\link{tfb_sigmoid}},
  \code{\link{tfb_softmax_centered}},
  \code{\link{tfb_softplus}}, \code{\link{tfb_softsign}},
  \code{\link{tfb_square}}, \code{\link{tfb_tanh}},
  \code{\link{tfb_transform_diagonal}},
  \code{\link{tfb_transpose}}, \code{\link{tfb_weibull}}
}
\concept{bijectors}
