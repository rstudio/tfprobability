<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Fit a surrogate posterior to a target (unnormalized) log density — vi_fit_surrogate_posterior • tfprobability</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Fit a surrogate posterior to a target (unnormalized) log density — vi_fit_surrogate_posterior" />
<meta property="og:description" content="The default behavior constructs and minimizes the negative variational
evidence lower bound (ELBO), given byq_samples &amp;lt;- surrogate_posterior$sample(num_draws)
elbo_loss &amp;lt;- -tf$reduce_mean(target_log_prob_fn(q_samples) - surrogate_posterior$log_prob(q_samples))

" />
<meta name="twitter:card" content="summary" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tfprobability</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.7.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/dynamic_linear_models.html">Dynamic linear models</a>
    </li>
    <li>
      <a href="../articles/hamiltonian_monte_carlo.html">Multi-level modeling with Hamiltonian Monte Carlo</a>
    </li>
    <li>
      <a href="../articles/layer_dense_variational.html">Uncertainty estimates with layer_dense_variational</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Fit a surrogate posterior to a target (unnormalized) log density</h1>
    
    <div class="hidden name"><code>vi_fit_surrogate_posterior.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>The default behavior constructs and minimizes the negative variational
evidence lower bound (ELBO), given by</p><pre>q_samples &lt;- surrogate_posterior$sample(num_draws)
elbo_loss &lt;- -tf$reduce_mean(target_log_prob_fn(q_samples) - surrogate_posterior$log_prob(q_samples))
</pre>

    </div>

    <pre class="usage"><span class='fu'>vi_fit_surrogate_posterior</span>(<span class='no'>target_log_prob_fn</span>, <span class='no'>surrogate_posterior</span>,
  <span class='no'>optimizer</span>, <span class='no'>num_steps</span>, <span class='kw'>trace_fn</span> <span class='kw'>=</span> <span class='kw'>function</span>(<span class='no'>loss</span>, <span class='no'>grads</span>, <span class='no'>variables</span>) <span class='no'>loss</span>,
  <span class='kw'>variational_loss_fn</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>sample_size</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>trainable_variables</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>seed</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>name</span> <span class='kw'>=</span> <span class='st'>"fit_surrogate_posterior"</span>)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>target_log_prob_fn</th>
      <td><p>function that takes a set of <code>Tensor</code> arguments
and returns a <code>Tensor</code> log-density. Given
<code>q_sample &lt;- surrogate_posterior$sample(sample_size)</code>, this
will be (in Python) called as <code>target_log_prob_fn(q_sample)</code> if <code>q_sample</code> is a list
or a tuple, <code>target_log_prob_fn(**q_sample)</code> if <code>q_sample</code> is a
dictionary, or <code>target_log_prob_fn(q_sample)</code> if <code>q_sample</code> is a <code>Tensor</code>.
It should support batched evaluation, i.e., should return a result of
shape <code>[sample_size]</code>.</p></td>
    </tr>
    <tr>
      <th>surrogate_posterior</th>
      <td><p>A <code>tfp$distributions$Distribution</code>
instance defining a variational posterior (could be a
<code>tfp$distributions$JointDistribution</code>). Crucially, the distribution's <code>log_prob</code> and
(if reparameterized) <code>sample</code> methods must directly invoke all ops
that generate gradients to the underlying variables. One way to ensure
this is to use <code>tfp$util$DeferredTensor</code> to represent any parameters
defined as transformations of unconstrained variables, so that the
transformations execute at runtime instead of at distribution creation.</p></td>
    </tr>
    <tr>
      <th>optimizer</th>
      <td><p>Optimizer instance to use. This may be a TF1-style
<code>tf$train$Optimizer</code>, TF2-style <code>tf$optimizers$Optimizer</code>, or any Python-compatible
object that implements <code>optimizer$apply_gradients(grads_and_vars)</code>.</p></td>
    </tr>
    <tr>
      <th>num_steps</th>
      <td><p><code>integer</code> number of steps to run the optimizer.</p></td>
    </tr>
    <tr>
      <th>trace_fn</th>
      <td><p>function with signature <code>state = trace_fn(loss, grads, variables)</code>,
where <code>state</code> may be a <code>Tensor</code> or nested structure of <code>Tensor</code>s.
The state values are accumulated (by <code>tf$scan</code>)
and returned. The default <code>trace_fn</code> simply returns the loss, but in
general can depend on the gradients and variables (if
<code>trainable_variables</code> is not <code>NULL</code> then <code>variables==trainable_variables</code>;
otherwise it is the list of all variables accessed during execution of
<code>loss_fn()</code>), as well as any other quantities captured in the closure of
<code>trace_fn</code>, for example, statistics of a variational distribution.
Default value: <code>function(loss, grads, variables) loss</code>.</p></td>
    </tr>
    <tr>
      <th>variational_loss_fn</th>
      <td><p>function with signature
<code>loss &lt;- variational_loss_fn(target_log_prob_fn, surrogate_posterior, sample_size, seed)</code>
defining a variational loss function. The default is
a Monte Carlo approximation to the standard evidence lower bound (ELBO),
equivalent to minimizing the 'reverse' <code>KL[q||p]</code> divergence between the
surrogate <code>q</code> and true posterior <code>p</code>.
Default value: <code>functools.partial(tfp.vi.monte_carlo_variational_loss, discrepancy_fn=tfp.vi.kl_reverse, use_reparameterization=True)</code>.</p></td>
    </tr>
    <tr>
      <th>sample_size</th>
      <td><p><code>integer</code> number of Monte Carlo samples to use
in estimating the variational divergence. Larger values may stabilize
the optimization, but at higher cost per step in time and memory.
Default value: <code>1</code>.</p></td>
    </tr>
    <tr>
      <th>trainable_variables</th>
      <td><p>Optional list of <code>tf$Variable</code> instances to optimize
with respect to. If <code>NULL</code>, defaults to the set of all variables accessed
during the computation of the variational bound, i.e., those defining
<code>surrogate_posterior</code> and the model <code>target_log_prob_fn</code>. Default value: <code>NULL</code>.</p></td>
    </tr>
    <tr>
      <th>seed</th>
      <td><p>integer to seed the random number generator.</p></td>
    </tr>
    <tr>
      <th>name</th>
      <td><p>name prefixed to ops created by this function. Default value: 'fit_surrogate_posterior'.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>results <code>Tensor</code> or nested structure of <code>Tensor</code>s, according to the
return type of <code>result_fn</code>. Each <code>Tensor</code> has an added leading dimension
of size <code>num_steps</code>, packing the trajectory of the result over the course of the optimization.</p>
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>This corresponds to minimizing the 'reverse' Kullback-Liebler divergence
(<code>KL[q||p]</code>) between the variational distribution and the unnormalized
<code>target_log_prob_fn</code>, and  defines a lower bound on the marginal log
likelihood, <code>log p(x) &gt;= -elbo_loss</code>.</p>
<p>More generally, this function supports fitting variational distributions that
minimize any <a href='https://en.wikipedia.org/wiki/F-divergence'>Csiszar f-divergence</a>.</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>Other vi-functions: <code><a href='vi_amari_alpha.html'>vi_amari_alpha</a></code>,
  <code><a href='vi_arithmetic_geometric.html'>vi_arithmetic_geometric</a></code>,
  <code><a href='vi_chi_square.html'>vi_chi_square</a></code>,
  <code><a href='vi_csiszar_vimco.html'>vi_csiszar_vimco</a></code>,
  <code><a href='vi_dual_csiszar_function.html'>vi_dual_csiszar_function</a></code>,
  <code><a href='vi_jeffreys.html'>vi_jeffreys</a></code>,
  <code><a href='vi_jensen_shannon.html'>vi_jensen_shannon</a></code>,
  <code><a href='vi_kl_forward.html'>vi_kl_forward</a></code>, <code><a href='vi_kl_reverse.html'>vi_kl_reverse</a></code>,
  <code><a href='vi_log1p_abs.html'>vi_log1p_abs</a></code>,
  <code><a href='vi_modified_gan.html'>vi_modified_gan</a></code>,
  <code><a href='vi_monte_carlo_variational_loss.html'>vi_monte_carlo_variational_loss</a></code>,
  <code><a href='vi_pearson.html'>vi_pearson</a></code>,
  <code><a href='vi_squared_hellinger.html'>vi_squared_hellinger</a></code>,
  <code><a href='vi_symmetrized_csiszar_function.html'>vi_symmetrized_csiszar_function</a></code></p></div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      <li><a href="#value">Value</a></li>
      <li><a href="#details">Details</a></li>
      <li><a href="#see-also">See also</a></li>
    </ul>

  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Sigrid Keydana.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


