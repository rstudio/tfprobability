<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Adapts the inner kernel's <code>step_size</code> based on <code>log_accept_prob</code>. — mcmc_simple_step_size_adaptation • tfprobability</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Adapts the inner kernel's <code>step_size</code> based on <code>log_accept_prob</code>. — mcmc_simple_step_size_adaptation" />

<meta property="og:description" content="The simple policy multiplicatively increases or decreases the step_size of
the inner kernel based on the value of log_accept_prob. It is based on
equation 19 of Andrieu and Thoms (2008). Given enough steps and small
enough adaptation_rate the median of the distribution of the acceptance
probability will converge to the target_accept_prob. A good target
acceptance probability depends on the inner kernel. If this kernel is
HamiltonianMonteCarlo, then 0.6-0.9 is a good range to aim for. For
RandomWalkMetropolis this should be closer to 0.25. See the individual
kernels' docstrings for guidance." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tfprobability</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.7.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/dynamic_linear_models.html">Dynamic linear models</a>
    </li>
    <li>
      <a href="../articles/hamiltonian_monte_carlo.html">Multi-level modeling with Hamiltonian Monte Carlo</a>
    </li>
    <li>
      <a href="../articles/layer_dense_variational.html">Uncertainty estimates with layer_dense_variational</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Adapts the inner kernel's <code>step_size</code> based on <code>log_accept_prob</code>.</h1>
    
    <div class="hidden name"><code>mcmc_simple_step_size_adaptation.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>The simple policy multiplicatively increases or decreases the <code>step_size</code> of
the inner kernel based on the value of <code>log_accept_prob</code>. It is based on
equation 19 of Andrieu and Thoms (2008). Given enough steps and small
enough <code>adaptation_rate</code> the median of the distribution of the acceptance
probability will converge to the <code>target_accept_prob</code>. A good target
acceptance probability depends on the inner kernel. If this kernel is
<code>HamiltonianMonteCarlo</code>, then 0.6-0.9 is a good range to aim for. For
<code>RandomWalkMetropolis</code> this should be closer to 0.25. See the individual
kernels' docstrings for guidance.</p>
    
    </div>

    <pre class="usage"><span class='fu'>mcmc_simple_step_size_adaptation</span>(<span class='no'>inner_kernel</span>, <span class='no'>num_adaptation_steps</span>,
  <span class='kw'>target_accept_prob</span> <span class='kw'>=</span> <span class='fl'>0.75</span>, <span class='kw'>adaptation_rate</span> <span class='kw'>=</span> <span class='fl'>0.01</span>,
  <span class='kw'>step_size_setter_fn</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>step_size_getter_fn</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>log_accept_prob_getter_fn</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>validate_args</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>name</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>inner_kernel</th>
      <td><p><code>TransitionKernel</code>-like object.</p></td>
    </tr>
    <tr>
      <th>num_adaptation_steps</th>
      <td><p>Scalar <code>integer</code> <code>Tensor</code> number of initial steps to
during which to adjust the step size. This may be greater, less than, or
equal to the number of burnin steps.</p></td>
    </tr>
    <tr>
      <th>target_accept_prob</th>
      <td><p>A floating point <code>Tensor</code> representing desired
acceptance probability. Must be a positive number less than 1. This can
either be a scalar, or have shape <code><a href='https://www.rdocumentation.org/packages/base/topics/list'>list(num_chains)</a></code>. Default value: <code>0.75</code>
(the center of asymptotically optimal rate for HMC).</p></td>
    </tr>
    <tr>
      <th>adaptation_rate</th>
      <td><p><code>Tensor</code> representing amount to scale the current
<code>step_size</code>.</p></td>
    </tr>
    <tr>
      <th>step_size_setter_fn</th>
      <td><p>A function with the signature
<code>(kernel_results, new_step_size) -&gt; new_kernel_results</code> where
<code>kernel_results</code> are the results of the <code>inner_kernel</code>, <code>new_step_size</code>
is a <code>Tensor</code> or a nested collection of <code>Tensor</code>s with the same
structure as returned by the <code>step_size_getter_fn</code>, and
<code>new_kernel_results</code> are a copy of <code>kernel_results</code> with the step
size(s) set.</p></td>
    </tr>
    <tr>
      <th>step_size_getter_fn</th>
      <td><p>A function with the signature
<code>(kernel_results) -&gt; step_size</code> where <code>kernel_results</code> are the results
of the <code>inner_kernel</code>, and <code>step_size</code> is a floating point <code>Tensor</code> or a
nested collection of such <code>Tensor</code>s.</p></td>
    </tr>
    <tr>
      <th>log_accept_prob_getter_fn</th>
      <td><p>A function with the signature
<code>(kernel_results) -&gt; log_accept_prob</code> where <code>kernel_results</code> are the
results of the <code>inner_kernel</code>, and <code>log_accept_prob</code> is a floating point
<code>Tensor</code>. <code>log_accept_prob</code> can either be a scalar, or have shape
<code><a href='https://www.rdocumentation.org/packages/base/topics/list'>list(num_chains)</a></code>. If it's the latter, <code>step_size</code> should also have the same
leading dimension.</p></td>
    </tr>
    <tr>
      <th>validate_args</th>
      <td><p><code>Logical</code>. When <code>True</code> kernel parameters are checked
for validity. When <code>False</code> invalid inputs may silently render incorrect
outputs.</p></td>
    </tr>
    <tr>
      <th>name</th>
      <td><p>string prefixed to Ops created by this class. Default: "simple_step_size_adaptation".</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>In general, adaptation prevents the chain from reaching a stationary
distribution, so obtaining consistent samples requires <code>num_adaptation_steps</code>
be set to a value somewhat smaller than the number of burnin steps.
However, it may sometimes be helpful to set <code>num_adaptation_steps</code> to a larger
value during development in order to inspect the behavior of the chain during
adaptation.</p>
<p>The step size is assumed to broadcast with the chain state, potentially having
leading dimensions corresponding to multiple chains. When there are fewer of
those leading dimensions than there are chain dimensions, the corresponding
dimensions in the <code>log_accept_prob</code> are averaged (in the direct space, rather
than the log space) before being used to adjust the step size. This means that
this kernel can do both cross-chain adaptation, or per-chain step size
adaptation, depending on the shape of the step size.</p>
<p>For example, if your problem has a state with shape <code>[S]</code>, your chain state
has shape <code>[C0, C1, Y]</code> (meaning that there are <code>C0 * C1</code> total chains) and
<code>log_accept_prob</code> has shape <code>[C0, C1]</code> (one acceptance probability per chain),
then depending on the shape of the step size, the following will happen:</p><ul>
<li><p>Step size has shape <code>[]</code>, <code>[S]</code> or <code>[1]</code>, the <code>log_accept_prob</code> will be averaged
across its <code>C0</code> and <code>C1</code> dimensions. This means that you will learn a shared
step size based on the mean acceptance probability across all chains. This
can be useful if you don't have a lot of steps to adapt and want to average
away the noise.</p></li>
<li><p>Step size has shape <code>[C1, 1]</code> or <code>[C1, S]</code>, the <code>log_accept_prob</code> will be
averaged across its <code>C0</code> dimension. This means that you will learn a shared
step size based on the mean acceptance probability across chains that share
the coordinate across the <code>C1</code> dimension. This can be useful when the <code>C1</code>
dimension indexes different distributions, while <code>C0</code> indexes replicas of a
single distribution, all sampled in parallel.</p></li>
<li><p>Step size has shape <code>[C0, C1, 1]</code> or <code>[C0, C1, S]</code>, then no averaging will
happen. This means that each chain will learn its own step size. This can be
useful when all chains are sampling from different distributions. Even when
all chains are for the same distribution, this can help during the initial
warmup period.</p></li>
<li><p>Step size has shape <code>[C0, 1, 1]</code> or <code>[C0, 1, S]</code>, the <code>log_accept_prob</code> will be
averaged across its <code>C1</code> dimension. This means that you will learn a shared
step size based on the mean acceptance probability across chains that share
the coordinate across the <code>C0</code> dimension. This can be useful when the <code>C0</code>
dimension indexes different distributions, while <code>C1</code> indexes replicas of a
single distribution, all sampled in parallel.</p></li>
</ul>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    
    <ul>
<li><p><a href='https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf'>Andrieu, Christophe, Thoms, Johannes. A tutorial on adaptive MCMC. Statistics and Computing, 2008.</a></p></li>
<li><p>http://andrewgelman.com/2017/12/15/burn-vs-warm-iterative-simulation-algorithms/#comment-627745</p></li>
<li><p><a href='http://arxiv.org/abs/1411.6669'>Betancourt, M. J., Byrne, S., &amp; Girolami, M. (2014). Optimizing The Integrator Step Size for Hamiltonian Monte Carlo.</a></p></li>
</ul>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>Other mcmc_kernels: <code><a href='mcmc_hamiltonian_monte_carlo.html'>mcmc_hamiltonian_monte_carlo</a></code>,
  <code><a href='mcmc_metropolis_hastings.html'>mcmc_metropolis_hastings</a></code>,
  <code><a href='mcmc_random_walk_metropolis.html'>mcmc_random_walk_metropolis</a></code>,
  <code><a href='mcmc_transformed_transition_kernel.html'>mcmc_transformed_transition_kernel</a></code>,
  <code><a href='mcmc_uncalibrated_hamiltonian_monte_carlo.html'>mcmc_uncalibrated_hamiltonian_monte_carlo</a></code></p></div>
    

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
          </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Sigrid Keydana.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

