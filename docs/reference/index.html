<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Function reference â€¢ tfprobability</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Function reference" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-index">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tfprobability</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.11.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/dynamic_linear_models.html">Dynamic linear models</a>
    </li>
    <li>
      <a href="../articles/hamiltonian_monte_carlo.html">Multi-level modeling with Hamiltonian Monte Carlo</a>
    </li>
    <li>
      <a href="../articles/layer_dense_variational.html">Uncertainty estimates with layer_dense_variational</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/rstudio/tfprobability/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="contents col-md-9">
    <div class="page-header">
      <h1>Reference</h1>
    </div>

    <table class="ref-index">

    <colgroup>
      
      <col class="alias" />
      <col class="title" />
    </colgroup>

    <tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-distributions" class="hasAnchor"><a href="#section-distributions" class="anchor"></a>Distributions</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="tfd_autoregressive.html">tfd_autoregressive()</a></code> </p>
        </td>
        <td><p>Autoregressive distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_batch_reshape.html">tfd_batch_reshape()</a></code> </p>
        </td>
        <td><p>Batch-Reshaping distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_bates.html">tfd_bates()</a></code> </p>
        </td>
        <td><p>Bates distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_bernoulli.html">tfd_bernoulli()</a></code> </p>
        </td>
        <td><p>Bernoulli distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_beta.html">tfd_beta()</a></code> </p>
        </td>
        <td><p>Beta distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_beta_binomial.html">tfd_beta_binomial()</a></code> </p>
        </td>
        <td><p>Beta-Binomial compound distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_binomial.html">tfd_binomial()</a></code> </p>
        </td>
        <td><p>Binomial distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_categorical.html">tfd_categorical()</a></code> </p>
        </td>
        <td><p>Categorical distribution over integers</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_cauchy.html">tfd_cauchy()</a></code> </p>
        </td>
        <td><p>Cauchy distribution with location <code>loc</code> and scale <code>scale</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_chi.html">tfd_chi()</a></code> </p>
        </td>
        <td><p>Chi distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_chi2.html">tfd_chi2()</a></code> </p>
        </td>
        <td><p>Chi Square distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_cholesky_lkj.html">tfd_cholesky_lkj()</a></code> </p>
        </td>
        <td><p>The CholeskyLKJ distribution on cholesky factors of correlation matrices</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_continuous_bernoulli.html">tfd_continuous_bernoulli()</a></code> </p>
        </td>
        <td><p>Continuous Bernoulli distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_deterministic.html">tfd_deterministic()</a></code> </p>
        </td>
        <td><p>Scalar <code>Deterministic</code> distribution on the real line</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_dirichlet.html">tfd_dirichlet()</a></code> </p>
        </td>
        <td><p>Dirichlet distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_dirichlet_multinomial.html">tfd_dirichlet_multinomial()</a></code> </p>
        </td>
        <td><p>Dirichlet-Multinomial compound distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_empirical.html">tfd_empirical()</a></code> </p>
        </td>
        <td><p>Empirical distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_exponential.html">tfd_exponential()</a></code> </p>
        </td>
        <td><p>Exponential distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_gamma.html">tfd_gamma()</a></code> </p>
        </td>
        <td><p>Gamma distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_gamma_gamma.html">tfd_gamma_gamma()</a></code> </p>
        </td>
        <td><p>Gamma-Gamma distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_gaussian_process.html">tfd_gaussian_process()</a></code> </p>
        </td>
        <td><p>Marginal distribution of a Gaussian process at finitely many points.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_gaussian_process_regression_model.html">tfd_gaussian_process_regression_model()</a></code> </p>
        </td>
        <td><p>Posterior predictive distribution in a conjugate GP regression model.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_generalized_normal.html">tfd_generalized_normal()</a></code> </p>
        </td>
        <td><p>The Generalized Normal distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_geometric.html">tfd_geometric()</a></code> </p>
        </td>
        <td><p>Geometric distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_gumbel.html">tfd_gumbel()</a></code> </p>
        </td>
        <td><p>Scalar Gumbel distribution with location <code>loc</code> and <code>scale</code> parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_half_cauchy.html">tfd_half_cauchy()</a></code> </p>
        </td>
        <td><p>Half-Cauchy distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_half_normal.html">tfd_half_normal()</a></code> </p>
        </td>
        <td><p>Half-Normal distribution with scale <code>scale</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_hidden_markov_model.html">tfd_hidden_markov_model()</a></code> </p>
        </td>
        <td><p>Hidden Markov model distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_horseshoe.html">tfd_horseshoe()</a></code> </p>
        </td>
        <td><p>Horseshoe distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_independent.html">tfd_independent()</a></code> </p>
        </td>
        <td><p>Independent distribution from batch of distributions</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_inverse_gamma.html">tfd_inverse_gamma()</a></code> </p>
        </td>
        <td><p>InverseGamma distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_inverse_gaussian.html">tfd_inverse_gaussian()</a></code> </p>
        </td>
        <td><p>Inverse Gaussian distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_johnson_s_u.html">tfd_johnson_s_u()</a></code> </p>
        </td>
        <td><p>Johnson's SU-distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_joint_distribution_named.html">tfd_joint_distribution_named()</a></code> </p>
        </td>
        <td><p>Joint distribution parameterized by named distribution-making functions.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_joint_distribution_named_auto_batched.html">tfd_joint_distribution_named_auto_batched()</a></code> </p>
        </td>
        <td><p>Joint distribution parameterized by named distribution-making functions.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_joint_distribution_sequential.html">tfd_joint_distribution_sequential()</a></code> </p>
        </td>
        <td><p>Joint distribution parameterized by distribution-making functions</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_joint_distribution_sequential_auto_batched.html">tfd_joint_distribution_sequential_auto_batched()</a></code> </p>
        </td>
        <td><p>Joint distribution parameterized by distribution-making functions.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_kumaraswamy.html">tfd_kumaraswamy()</a></code> </p>
        </td>
        <td><p>Kumaraswamy distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_laplace.html">tfd_laplace()</a></code> </p>
        </td>
        <td><p>Laplace distribution with location <code>loc</code> and <code>scale</code> parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_linear_gaussian_state_space_model.html">tfd_linear_gaussian_state_space_model()</a></code> </p>
        </td>
        <td><p>Observation distribution from a linear Gaussian state space model</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_lkj.html">tfd_lkj()</a></code> </p>
        </td>
        <td><p>LKJ distribution on correlation matrices</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_log_logistic.html">tfd_log_logistic()</a></code> </p>
        </td>
        <td><p>The log-logistic distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_log_normal.html">tfd_log_normal()</a></code> <code><a href="tfd_log_normal.html">tfd_log_normal()</a></code> </p>
        </td>
        <td><p>Log-normal distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_logistic.html">tfd_logistic()</a></code> </p>
        </td>
        <td><p>Logistic distribution with location <code>loc</code> and <code>scale</code> parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_mixture.html">tfd_mixture()</a></code> </p>
        </td>
        <td><p>Mixture distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_mixture_same_family.html">tfd_mixture_same_family()</a></code> </p>
        </td>
        <td><p>Mixture (same-family) distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multinomial.html">tfd_multinomial()</a></code> </p>
        </td>
        <td><p>Multinomial distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multivariate_normal_diag.html">tfd_multivariate_normal_diag()</a></code> </p>
        </td>
        <td><p>Multivariate normal distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multivariate_normal_diag_plus_low_rank.html">tfd_multivariate_normal_diag_plus_low_rank()</a></code> </p>
        </td>
        <td><p>Multivariate normal distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multivariate_normal_full_covariance.html">tfd_multivariate_normal_full_covariance()</a></code> </p>
        </td>
        <td><p>Multivariate normal distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multivariate_normal_linear_operator.html">tfd_multivariate_normal_linear_operator()</a></code> </p>
        </td>
        <td><p>The multivariate normal distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multivariate_normal_tri_l.html">tfd_multivariate_normal_tri_l()</a></code> </p>
        </td>
        <td><p>The multivariate normal distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_multivariate_student_t_linear_operator.html">tfd_multivariate_student_t_linear_operator()</a></code> </p>
        </td>
        <td><p>Multivariate Student's t-distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_negative_binomial.html">tfd_negative_binomial()</a></code> </p>
        </td>
        <td><p>NegativeBinomial distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_normal.html">tfd_normal()</a></code> </p>
        </td>
        <td><p>Normal distribution with loc and scale parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_one_hot_categorical.html">tfd_one_hot_categorical()</a></code> </p>
        </td>
        <td><p>OneHotCategorical distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_pareto.html">tfd_pareto()</a></code> </p>
        </td>
        <td><p>Pareto distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_pixel_cnn.html">tfd_pixel_cnn()</a></code> </p>
        </td>
        <td><p>The Pixel CNN++ distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_poisson.html">tfd_poisson()</a></code> </p>
        </td>
        <td><p>Poisson distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_poisson_log_normal_quadrature_compound.html">tfd_poisson_log_normal_quadrature_compound()</a></code> </p>
        </td>
        <td><p><code>PoissonLogNormalQuadratureCompound</code> distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_power_spherical.html">tfd_power_spherical()</a></code> </p>
        </td>
        <td><p>The Power Spherical distribution over unit vectors on <code>S^{n-1}</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_probit_bernoulli.html">tfd_probit_bernoulli()</a></code> </p>
        </td>
        <td><p>ProbitBernoulli distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_quantized.html">tfd_quantized()</a></code> </p>
        </td>
        <td><p>Distribution representing the quantization <code>Y = ceiling(X)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_relaxed_bernoulli.html">tfd_relaxed_bernoulli()</a></code> </p>
        </td>
        <td><p>RelaxedBernoulli distribution with temperature and logits parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_relaxed_one_hot_categorical.html">tfd_relaxed_one_hot_categorical()</a></code> </p>
        </td>
        <td><p>RelaxedOneHotCategorical distribution with temperature and logits</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_sample_distribution.html">tfd_sample_distribution()</a></code> </p>
        </td>
        <td><p>Sample distribution via independent draws.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_sinh_arcsinh.html">tfd_sinh_arcsinh()</a></code> </p>
        </td>
        <td><p>The SinhArcsinh transformation of a distribution on <code>(-inf, inf)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_spherical_uniform.html">tfd_spherical_uniform()</a></code> </p>
        </td>
        <td><p>The uniform distribution over unit vectors on <code>S^{n-1}</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_student_t.html">tfd_student_t()</a></code> </p>
        </td>
        <td><p>Student's t-distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_student_t_process.html">tfd_student_t_process()</a></code> </p>
        </td>
        <td><p>Marginal distribution of a Student's T process at finitely many points</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_transformed_distribution.html">tfd_transformed_distribution()</a></code> </p>
        </td>
        <td><p>A Transformed Distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_triangular.html">tfd_triangular()</a></code> </p>
        </td>
        <td><p>Triangular distribution with <code>low</code>, <code>high</code> and <code>peak</code> parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_truncated_cauchy.html">tfd_truncated_cauchy()</a></code> </p>
        </td>
        <td><p>The Truncated Cauchy distribution.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_truncated_normal.html">tfd_truncated_normal()</a></code> </p>
        </td>
        <td><p>Truncated Normal distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_uniform.html">tfd_uniform()</a></code> </p>
        </td>
        <td><p>Uniform distribution with <code>low</code> and <code>high</code> parameters</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_variational_gaussian_process.html">tfd_variational_gaussian_process()</a></code> </p>
        </td>
        <td><p>Posterior predictive of a variational Gaussian process</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_vector_diffeomixture.html">tfd_vector_diffeomixture()</a></code> </p>
        </td>
        <td><p>VectorDiffeomixture distribution</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_vector_exponential_diag.html">tfd_vector_exponential_diag()</a></code> </p>
        </td>
        <td><p>The vectorization of the Exponential distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_vector_exponential_linear_operator.html">tfd_vector_exponential_linear_operator()</a></code> </p>
        </td>
        <td><p>The vectorization of the Exponential distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_vector_laplace_diag.html">tfd_vector_laplace_diag()</a></code> </p>
        </td>
        <td><p>The vectorization of the Laplace distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_vector_laplace_linear_operator.html">tfd_vector_laplace_linear_operator()</a></code> </p>
        </td>
        <td><p>The vectorization of the Laplace distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_vector_sinh_arcsinh_diag.html">tfd_vector_sinh_arcsinh_diag()</a></code> </p>
        </td>
        <td><p>The (diagonal) SinhArcsinh transformation of a distribution on <code>R^k</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_von_mises.html">tfd_von_mises()</a></code> </p>
        </td>
        <td><p>The von Mises distribution over angles</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_von_mises_fisher.html">tfd_von_mises_fisher()</a></code> </p>
        </td>
        <td><p>The von Mises-Fisher distribution over unit vectors on <code>S^{n-1}</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_weibull.html">tfd_weibull()</a></code> </p>
        </td>
        <td><p>The Weibull distribution with 'concentration' and <code>scale</code> parameters.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_wishart.html">tfd_wishart()</a></code> </p>
        </td>
        <td><p>The matrix Wishart distribution on positive definite matrices</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_wishart_linear_operator.html">tfd_wishart_linear_operator()</a></code> </p>
        </td>
        <td><p>The matrix Wishart distribution on positive definite matrices</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_wishart_tri_l.html">tfd_wishart_tri_l()</a></code> </p>
        </td>
        <td><p>The matrix Wishart distribution parameterized with Cholesky factors.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_zipf.html">tfd_zipf()</a></code> </p>
        </td>
        <td><p>Zipf distribution</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-distribution-methods" class="hasAnchor"><a href="#section-distribution-methods" class="anchor"></a>Distribution methods</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="tfd_cdf.html">tfd_cdf()</a></code> </p>
        </td>
        <td><p>Cumulative distribution function.
Given random variable X, the cumulative distribution function cdf is:
<code>cdf(x) := P[X &lt;= x]</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_covariance.html">tfd_covariance()</a></code> </p>
        </td>
        <td><p>Covariance.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_cross_entropy.html">tfd_cross_entropy()</a></code> </p>
        </td>
        <td><p>Computes the (Shannon) cross entropy.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_entropy.html">tfd_entropy()</a></code> </p>
        </td>
        <td><p>Shannon entropy in nats.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_kl_divergence.html">tfd_kl_divergence()</a></code> </p>
        </td>
        <td><p>Computes the Kullback--Leibler divergence.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_log_cdf.html">tfd_log_cdf()</a></code> </p>
        </td>
        <td><p>Log cumulative distribution function.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_log_prob.html">tfd_log_prob()</a></code> </p>
        </td>
        <td><p>Log probability density/mass function.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_log_survival_function.html">tfd_log_survival_function()</a></code> </p>
        </td>
        <td><p>Log survival function.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_mean.html">tfd_mean()</a></code> </p>
        </td>
        <td><p>Mean.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_mode.html">tfd_mode()</a></code> </p>
        </td>
        <td><p>Mode.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_prob.html">tfd_prob()</a></code> </p>
        </td>
        <td><p>Probability density/mass function.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_quantile.html">tfd_quantile()</a></code> </p>
        </td>
        <td><p>Quantile function. Aka "inverse cdf" or "percent point function".</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_sample.html">tfd_sample()</a></code> </p>
        </td>
        <td><p>Generate samples of the specified shape.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_stddev.html">tfd_stddev()</a></code> </p>
        </td>
        <td><p>Standard deviation.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_survival_function.html">tfd_survival_function()</a></code> </p>
        </td>
        <td><p>Survival function.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfd_variance.html">tfd_variance()</a></code> </p>
        </td>
        <td><p>Variance.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-keras-layers-distribution-layers" class="hasAnchor"><a href="#section-keras-layers-distribution-layers" class="anchor"></a>Keras layers: Distribution layers</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="layer_categorical_mixture_of_one_hot_categorical.html">layer_categorical_mixture_of_one_hot_categorical()</a></code> </p>
        </td>
        <td><p>A OneHotCategorical mixture Keras layer from <code>k * (1 + d)</code> params.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_distribution_lambda.html">layer_distribution_lambda()</a></code> </p>
        </td>
        <td><p>Keras layer enabling plumbing TFP distributions through Keras models</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_independent_bernoulli.html">layer_independent_bernoulli()</a></code> </p>
        </td>
        <td><p>An Independent-Bernoulli Keras layer from prod(event_shape) params</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_independent_logistic.html">layer_independent_logistic()</a></code> </p>
        </td>
        <td><p>An independent Logistic Keras layer.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_independent_normal.html">layer_independent_normal()</a></code> </p>
        </td>
        <td><p>An independent Normal Keras layer.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_independent_poisson.html">layer_independent_poisson()</a></code> </p>
        </td>
        <td><p>An independent Poisson Keras layer.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_kl_divergence_add_loss.html">layer_kl_divergence_add_loss()</a></code> </p>
        </td>
        <td><p>Pass-through layer that adds a KL divergence penalty to the model loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_kl_divergence_regularizer.html">layer_kl_divergence_regularizer()</a></code> </p>
        </td>
        <td><p>Regularizer that adds a KL divergence penalty to the model loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_mixture_logistic.html">layer_mixture_logistic()</a></code> </p>
        </td>
        <td><p>A mixture distribution Keras layer, with independent logistic components.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_mixture_normal.html">layer_mixture_normal()</a></code> </p>
        </td>
        <td><p>A mixture distribution Keras layer, with independent normal components.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_mixture_same_family.html">layer_mixture_same_family()</a></code> </p>
        </td>
        <td><p>A mixture (same-family) Keras layer.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_multivariate_normal_tri_l.html">layer_multivariate_normal_tri_l()</a></code> </p>
        </td>
        <td><p>A d-variate Multivariate Normal TriL Keras layer from <code>d+d*(d+1)/ 2</code> params</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_one_hot_categorical.html">layer_one_hot_categorical()</a></code> </p>
        </td>
        <td><p>A <code>d</code>-variate OneHotCategorical Keras layer from <code>d</code> params.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-keras-layers-other" class="hasAnchor"><a href="#section-keras-layers-other" class="anchor"></a>Keras layers: Other</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="layer_autoregressive.html">layer_autoregressive()</a></code> </p>
        </td>
        <td><p>Masked Autoencoder for Distribution Estimation</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_conv_1d_flipout.html">layer_conv_1d_flipout()</a></code> </p>
        </td>
        <td><p>1D convolution layer (e.g. temporal convolution) with Flipout</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_conv_1d_reparameterization.html">layer_conv_1d_reparameterization()</a></code> </p>
        </td>
        <td><p>1D convolution layer (e.g. temporal convolution).</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_conv_2d_flipout.html">layer_conv_2d_flipout()</a></code> </p>
        </td>
        <td><p>2D convolution layer (e.g. spatial convolution over images) with Flipout</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_conv_2d_reparameterization.html">layer_conv_2d_reparameterization()</a></code> </p>
        </td>
        <td><p>2D convolution layer (e.g. spatial convolution over images)</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_conv_3d_flipout.html">layer_conv_3d_flipout()</a></code> </p>
        </td>
        <td><p>3D convolution layer (e.g. spatial convolution over volumes) with Flipout</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_conv_3d_reparameterization.html">layer_conv_3d_reparameterization()</a></code> </p>
        </td>
        <td><p>3D convolution layer (e.g. spatial convolution over volumes)</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_dense_flipout.html">layer_dense_flipout()</a></code> </p>
        </td>
        <td><p>Densely-connected layer class with Flipout estimator.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_dense_local_reparameterization.html">layer_dense_local_reparameterization()</a></code> </p>
        </td>
        <td><p>Densely-connected layer class with local reparameterization estimator.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_dense_reparameterization.html">layer_dense_reparameterization()</a></code> </p>
        </td>
        <td><p>Densely-connected layer class with reparameterization estimator.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_dense_variational.html">layer_dense_variational()</a></code> </p>
        </td>
        <td><p>Dense Variational Layer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="layer_variable.html">layer_variable()</a></code> </p>
        </td>
        <td><p>Variable Layer</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-bijectors" class="hasAnchor"><a href="#section-bijectors" class="anchor"></a>Bijectors</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="tfb_absolute_value.html">tfb_absolute_value()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = Abs(X)</code>, element-wise</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_affine.html">tfb_affine()</a></code> </p>
        </td>
        <td><p>Affine bijector</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_affine_linear_operator.html">tfb_affine_linear_operator()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X; shift, scale) = scale @ X + shift</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_affine_scalar.html">tfb_affine_scalar()</a></code> </p>
        </td>
        <td><p>AffineScalar bijector</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_batch_normalization.html">tfb_batch_normalization()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X)</code> s.t. <code>X = g^-1(Y) = (Y - mean(Y)) / std(Y)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_blockwise.html">tfb_blockwise()</a></code> </p>
        </td>
        <td><p>Bijector which applies a list of bijectors to blocks of a Tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_chain.html">tfb_chain()</a></code> </p>
        </td>
        <td><p>Bijector which applies a sequence of bijectors</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_cholesky_outer_product.html">tfb_cholesky_outer_product()</a></code> </p>
        </td>
        <td><p>Computes<code>g(X) = X @ X.T</code> where <code>X</code> is lower-triangular, positive-diagonal matrix</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_cholesky_to_inv_cholesky.html">tfb_cholesky_to_inv_cholesky()</a></code> </p>
        </td>
        <td><p>Maps the Cholesky factor of M to the Cholesky factor of <code>M^{-1}</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_correlation_cholesky.html">tfb_correlation_cholesky()</a></code> </p>
        </td>
        <td><p>Maps unconstrained reals to Cholesky-space correlation matrices.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_cumsum.html">tfb_cumsum()</a></code> </p>
        </td>
        <td><p>Computes the cumulative sum of a tensor along a specified axis.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_discrete_cosine_transform.html">tfb_discrete_cosine_transform()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = DCT(X)</code>, where DCT type is indicated by the type arg</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_exp.html">tfb_exp()</a></code> </p>
        </td>
        <td><p>Computes<code>Y=g(X)=exp(X)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_expm1.html">tfb_expm1()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = exp(X) - 1</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_ffjord.html">tfb_ffjord()</a></code> </p>
        </td>
        <td><p>Implements a continuous normalizing flow X-&gt;Y defined via an ODE.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_fill_scale_tri_l.html">tfb_fill_scale_tri_l()</a></code> </p>
        </td>
        <td><p>Transforms unconstrained vectors to TriL matrices with positive diagonal</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_fill_triangular.html">tfb_fill_triangular()</a></code> </p>
        </td>
        <td><p>Transforms vectors to triangular</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_gompertz_cdf.html">tfb_gompertz_cdf()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X) = 1 - exp(-c * (exp(rate * X) - 1)</code>, the Gompertz CDF.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_gumbel.html">tfb_gumbel()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = exp(-exp(-(X - loc) / scale))</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_gumbel_cdf.html">tfb_gumbel_cdf()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X) = exp(-exp(-(X - loc) / scale))</code>, the Gumbel CDF.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_identity.html">tfb_identity()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = X</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_inline.html">tfb_inline()</a></code> </p>
        </td>
        <td><p>Bijector constructed from custom functions</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_invert.html">tfb_invert()</a></code> </p>
        </td>
        <td><p>Bijector which inverts another Bijector</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_iterated_sigmoid_centered.html">tfb_iterated_sigmoid_centered()</a></code> </p>
        </td>
        <td><p>Bijector which applies a Stick Breaking procedure.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_kumaraswamy.html">tfb_kumaraswamy()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = (1 - (1 - X)**(1 / b))**(1 / a)</code>, with X in <code>[0, 1]</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_kumaraswamy_cdf.html">tfb_kumaraswamy_cdf()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = (1 - (1 - X)**(1 / b))**(1 / a)</code>, with X in <code>[0, 1]</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_lambert_w_tail.html">tfb_lambert_w_tail()</a></code> </p>
        </td>
        <td><p>LambertWTail transformation for heavy-tail Lambert W x F random variables.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_masked_autoregressive_default_template.html">tfb_masked_autoregressive_default_template()</a></code> </p>
        </td>
        <td><p>Masked Autoregressive Density Estimator</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_masked_autoregressive_flow.html">tfb_masked_autoregressive_flow()</a></code> </p>
        </td>
        <td><p>Affine MaskedAutoregressiveFlow bijector</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_masked_dense.html">tfb_masked_dense()</a></code> </p>
        </td>
        <td><p>Autoregressively masked dense layer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_matrix_inverse_tri_l.html">tfb_matrix_inverse_tri_l()</a></code> </p>
        </td>
        <td><p>Computes <code>g(L) = inv(L)</code>, where L is a lower-triangular matrix</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_matvec_lu.html">tfb_matvec_lu()</a></code> </p>
        </td>
        <td><p>Matrix-vector multiply using LU decomposition</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_normal_cdf.html">tfb_normal_cdf()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = NormalCDF(x)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_ordered.html">tfb_ordered()</a></code> </p>
        </td>
        <td><p>Bijector which maps a tensor x_k that has increasing elements in the last dimension to an unconstrained tensor y_k</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_pad.html">tfb_pad()</a></code> </p>
        </td>
        <td><p>Pads a value to the <code>event_shape</code> of a <code>Tensor</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_permute.html">tfb_permute()</a></code> </p>
        </td>
        <td><p>Permutes the rightmost dimension of a Tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_power_transform.html">tfb_power_transform()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = (1 + X * c)**(1 / c)</code>, where <code>X &gt;= -1 / c</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_rational_quadratic_spline.html">tfb_rational_quadratic_spline()</a></code> </p>
        </td>
        <td><p>A piecewise rational quadratic spline, as developed in Conor et al.(2019).</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_real_nvp.html">tfb_real_nvp()</a></code> </p>
        </td>
        <td><p>RealNVP affine coupling layer for vector-valued events</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_real_nvp_default_template.html">tfb_real_nvp_default_template()</a></code> </p>
        </td>
        <td><p>Build a scale-and-shift function using a multi-layer neural network</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_reciprocal.html">tfb_reciprocal()</a></code> </p>
        </td>
        <td><p>A Bijector that computes <code>b(x) = 1. / x</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_reshape.html">tfb_reshape()</a></code> </p>
        </td>
        <td><p>Reshapes the event_shape of a Tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_scale.html">tfb_scale()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X; scale) = scale * X</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_scale_matvec_diag.html">tfb_scale_matvec_diag()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X; scale) = scale @ X</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_scale_matvec_linear_operator.html">tfb_scale_matvec_linear_operator()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X; scale) = scale @ X</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_scale_matvec_lu.html">tfb_scale_matvec_lu()</a></code> </p>
        </td>
        <td><p>Matrix-vector multiply using LU decomposition.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_scale_matvec_tri_l.html">tfb_scale_matvec_tri_l()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X; scale) = scale @ X</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_scale_tri_l.html">tfb_scale_tri_l()</a></code> </p>
        </td>
        <td><p>Transforms unconstrained vectors to TriL matrices with positive diagonal</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_shift.html">tfb_shift()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X; shift) = X + shift</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_shifted_gompertz_cdf.html">tfb_shifted_gompertz_cdf()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X) = (1 - exp(-rate * X)) * exp(-c * exp(-rate * X))</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_sigmoid.html">tfb_sigmoid()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = 1 / (1 + exp(-X))</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_sinh.html">tfb_sinh()</a></code> </p>
        </td>
        <td><p>Bijector that computes <code>Y = sinh(X)</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_sinh_arcsinh.html">tfb_sinh_arcsinh()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = Sinh( (Arcsinh(X) + skewness) * tailweight )</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_softmax_centered.html">tfb_softmax_centered()</a></code> </p>
        </td>
        <td><p>Computes <code>Y = g(X) = exp([X 0]) / sum(exp([X 0]))</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_softplus.html">tfb_softplus()</a></code> </p>
        </td>
        <td><p>Computes <code>Y = g(X) = Log[1 + exp(X)]</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_softsign.html">tfb_softsign()</a></code> </p>
        </td>
        <td><p>Computes <code>Y = g(X) = X / (1 + |X|)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_split.html">tfb_split()</a></code> </p>
        </td>
        <td><p>Split a <code>Tensor</code> event along an axis into a list of <code>Tensor</code>s.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_square.html">tfb_square()</a></code> </p>
        </td>
        <td><p>Computes<code>g(X) = X^2</code>; X is a positive real number.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_tanh.html">tfb_tanh()</a></code> </p>
        </td>
        <td><p>Computes <code>Y = tanh(X)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_transform_diagonal.html">tfb_transform_diagonal()</a></code> </p>
        </td>
        <td><p>Applies a Bijector to the diagonal of a matrix</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_transpose.html">tfb_transpose()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = transpose_rightmost_dims(X, rightmost_perm)</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_weibull.html">tfb_weibull()</a></code> </p>
        </td>
        <td><p>Computes<code>Y = g(X) = 1 - exp((-X / scale) ** concentration)</code> where X &gt;= 0</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_weibull_cdf.html">tfb_weibull_cdf()</a></code> </p>
        </td>
        <td><p>Compute <code>Y = g(X) = 1 - exp((-X / scale) ** concentration), X &gt;= 0</code>.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-bijector-methods" class="hasAnchor"><a href="#section-bijector-methods" class="anchor"></a>Bijector methods</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="tfb_forward.html">tfb_forward()</a></code> </p>
        </td>
        <td><p>Returns the forward Bijector evaluation, i.e., <code>X = g(Y)</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_forward_log_det_jacobian.html">tfb_forward_log_det_jacobian()</a></code> </p>
        </td>
        <td><p>Returns the result of the forward evaluation of the log determinant of the Jacobian</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_inverse.html">tfb_inverse()</a></code> </p>
        </td>
        <td><p>Returns the inverse Bijector evaluation, i.e., <code>X = g^{-1}(Y)</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tfb_inverse_log_det_jacobian.html">tfb_inverse_log_det_jacobian()</a></code> </p>
        </td>
        <td><p>Returns the result of the inverse evaluation of the log determinant of the Jacobian</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-variational-inference" class="hasAnchor"><a href="#section-variational-inference" class="anchor"></a>Variational inference</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="vi_amari_alpha.html">vi_amari_alpha()</a></code> </p>
        </td>
        <td><p>The Amari-alpha Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_arithmetic_geometric.html">vi_arithmetic_geometric()</a></code> </p>
        </td>
        <td><p>The Arithmetic-Geometric Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_chi_square.html">vi_chi_square()</a></code> </p>
        </td>
        <td><p>The chi-square Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_csiszar_vimco.html">vi_csiszar_vimco()</a></code> </p>
        </td>
        <td><p>Use VIMCO to lower the variance of the gradient of csiszar_function(Avg(logu))</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_dual_csiszar_function.html">vi_dual_csiszar_function()</a></code> </p>
        </td>
        <td><p>Calculates the dual Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_fit_surrogate_posterior.html">vi_fit_surrogate_posterior()</a></code> </p>
        </td>
        <td><p>Fit a surrogate posterior to a target (unnormalized) log density</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_jeffreys.html">vi_jeffreys()</a></code> </p>
        </td>
        <td><p>The Jeffreys Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_jensen_shannon.html">vi_jensen_shannon()</a></code> </p>
        </td>
        <td><p>The Jensen-Shannon Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_kl_forward.html">vi_kl_forward()</a></code> </p>
        </td>
        <td><p>The forward Kullback-Leibler Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_kl_reverse.html">vi_kl_reverse()</a></code> </p>
        </td>
        <td><p>The reverse Kullback-Leibler Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_log1p_abs.html">vi_log1p_abs()</a></code> </p>
        </td>
        <td><p>The log1p-abs Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_modified_gan.html">vi_modified_gan()</a></code> </p>
        </td>
        <td><p>The Modified-GAN Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_monte_carlo_variational_loss.html">vi_monte_carlo_variational_loss()</a></code> </p>
        </td>
        <td><p>Monte-Carlo approximation of an f-Divergence variational loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_pearson.html">vi_pearson()</a></code> </p>
        </td>
        <td><p>The Pearson Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_squared_hellinger.html">vi_squared_hellinger()</a></code> </p>
        </td>
        <td><p>The Squared-Hellinger Csiszar-function in log-space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="vi_symmetrized_csiszar_function.html">vi_symmetrized_csiszar_function()</a></code> </p>
        </td>
        <td><p>Symmetrizes a Csiszar-function in log-space</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-mcmc-kernels" class="hasAnchor"><a href="#section-mcmc-kernels" class="anchor"></a>MCMC kernels</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="mcmc_dual_averaging_step_size_adaptation.html">mcmc_dual_averaging_step_size_adaptation()</a></code> </p>
        </td>
        <td><p>Adapts the inner kernel's <code>step_size</code> based on <code>log_accept_prob</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_hamiltonian_monte_carlo.html">mcmc_hamiltonian_monte_carlo()</a></code> </p>
        </td>
        <td><p>Runs one step of Hamiltonian Monte Carlo.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_metropolis_adjusted_langevin_algorithm.html">mcmc_metropolis_adjusted_langevin_algorithm()</a></code> </p>
        </td>
        <td><p>Runs one step of Metropolis-adjusted Langevin algorithm.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_metropolis_hastings.html">mcmc_metropolis_hastings()</a></code> </p>
        </td>
        <td><p>Runs one step of the Metropolis-Hastings algorithm.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_no_u_turn_sampler.html">mcmc_no_u_turn_sampler()</a></code> </p>
        </td>
        <td><p>Runs one step of the No U-Turn Sampler</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_random_walk_metropolis.html">mcmc_random_walk_metropolis()</a></code> </p>
        </td>
        <td><p>Runs one step of the RWM algorithm with symmetric proposal.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_replica_exchange_mc.html">mcmc_replica_exchange_mc()</a></code> </p>
        </td>
        <td><p>Runs one step of the Replica Exchange Monte Carlo</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_simple_step_size_adaptation.html">mcmc_simple_step_size_adaptation()</a></code> </p>
        </td>
        <td><p>Adapts the inner kernel's <code>step_size</code> based on <code>log_accept_prob</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_slice_sampler.html">mcmc_slice_sampler()</a></code> </p>
        </td>
        <td><p>Runs one step of the slice sampler using a hit and run approach</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_transformed_transition_kernel.html">mcmc_transformed_transition_kernel()</a></code> </p>
        </td>
        <td><p>Applies a bijector to the MCMC's state space</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_uncalibrated_hamiltonian_monte_carlo.html">mcmc_uncalibrated_hamiltonian_monte_carlo()</a></code> </p>
        </td>
        <td><p>Runs one step of Uncalibrated Hamiltonian Monte Carlo</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_uncalibrated_langevin.html">mcmc_uncalibrated_langevin()</a></code> </p>
        </td>
        <td><p>Runs one step of Uncalibrated Langevin discretized diffusion.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_uncalibrated_random_walk.html">mcmc_uncalibrated_random_walk()</a></code> </p>
        </td>
        <td><p>Generate proposal for the Random Walk Metropolis algorithm.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-mcmc-functions" class="hasAnchor"><a href="#section-mcmc-functions" class="anchor"></a>MCMC functions</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="mcmc_effective_sample_size.html">mcmc_effective_sample_size()</a></code> </p>
        </td>
        <td><p>Estimate a lower bound on effective sample size for each independent chain.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_potential_scale_reduction.html">mcmc_potential_scale_reduction()</a></code> </p>
        </td>
        <td><p>Gelman and Rubin (1992)'s potential scale reduction for chain convergence.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_sample_annealed_importance_chain.html">mcmc_sample_annealed_importance_chain()</a></code> </p>
        </td>
        <td><p>Runs annealed importance sampling (AIS) to estimate normalizing constants.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_sample_chain.html">mcmc_sample_chain()</a></code> </p>
        </td>
        <td><p>Implements Markov chain Monte Carlo via repeated <code>TransitionKernel</code> steps.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="mcmc_sample_halton_sequence.html">mcmc_sample_halton_sequence()</a></code> </p>
        </td>
        <td><p>Returns a sample from the <code>dim</code> dimensional Halton sequence.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-structural-time-series-models" class="hasAnchor"><a href="#section-structural-time-series-models" class="anchor"></a>Structural time series models</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="sts_additive_state_space_model.html">sts_additive_state_space_model()</a></code> </p>
        </td>
        <td><p>A state space model representing a sum of component state space models.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_autoregressive.html">sts_autoregressive()</a></code> </p>
        </td>
        <td><p>Formal representation of an autoregressive model.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_autoregressive_state_space_model.html">sts_autoregressive_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for an autoregressive process.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_constrained_seasonal_state_space_model.html">sts_constrained_seasonal_state_space_model()</a></code> </p>
        </td>
        <td><p>Seasonal state space model with effects constrained to sum to zero.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_dynamic_linear_regression.html">sts_dynamic_linear_regression()</a></code> </p>
        </td>
        <td><p>Formal representation of a dynamic linear regression model.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_dynamic_linear_regression_state_space_model.html">sts_dynamic_linear_regression_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for a dynamic linear regression from provided covariates.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_linear_regression.html">sts_linear_regression()</a></code> </p>
        </td>
        <td><p>Formal representation of a linear regression from provided covariates.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_local_level.html">sts_local_level()</a></code> </p>
        </td>
        <td><p>Formal representation of a local level model</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_local_level_state_space_model.html">sts_local_level_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for a local level</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_local_linear_trend.html">sts_local_linear_trend()</a></code> </p>
        </td>
        <td><p>Formal representation of a local linear trend model</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_local_linear_trend_state_space_model.html">sts_local_linear_trend_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for a local linear trend</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_seasonal.html">sts_seasonal()</a></code> </p>
        </td>
        <td><p>Formal representation of a seasonal effect model.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_seasonal_state_space_model.html">sts_seasonal_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for a seasonal effect.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_semi_local_linear_trend.html">sts_semi_local_linear_trend()</a></code> </p>
        </td>
        <td><p>Formal representation of a semi-local linear trend model.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_semi_local_linear_trend_state_space_model.html">sts_semi_local_linear_trend_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for a semi-local linear trend.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_smooth_seasonal.html">sts_smooth_seasonal()</a></code> </p>
        </td>
        <td><p>Formal representation of a smooth seasonal effect model</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_smooth_seasonal_state_space_model.html">sts_smooth_seasonal_state_space_model()</a></code> </p>
        </td>
        <td><p>State space model for a smooth seasonal effect</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_sparse_linear_regression.html">sts_sparse_linear_regression()</a></code> </p>
        </td>
        <td><p>Formal representation of a sparse linear regression.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_sum.html">sts_sum()</a></code> </p>
        </td>
        <td><p>Sum of structural time series components.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-structural-time-series-modeling-functions" class="hasAnchor"><a href="#section-structural-time-series-modeling-functions" class="anchor"></a>Structural time series modeling functions</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="sts_build_factored_surrogate_posterior.html">sts_build_factored_surrogate_posterior()</a></code> </p>
        </td>
        <td><p>Build a variational posterior that factors over model parameters.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_build_factored_variational_loss.html">sts_build_factored_variational_loss()</a></code> </p>
        </td>
        <td><p>Build a loss function for variational inference in STS models.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_decompose_by_component.html">sts_decompose_by_component()</a></code> </p>
        </td>
        <td><p>Decompose an observed time series into contributions from each component.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_decompose_forecast_by_component.html">sts_decompose_forecast_by_component()</a></code> </p>
        </td>
        <td><p>Decompose a forecast distribution into contributions from each component.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_fit_with_hmc.html">sts_fit_with_hmc()</a></code> </p>
        </td>
        <td><p>Draw posterior samples using Hamiltonian Monte Carlo (HMC)</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_forecast.html">sts_forecast()</a></code> </p>
        </td>
        <td><p>Construct predictive distribution over future observations</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_one_step_predictive.html">sts_one_step_predictive()</a></code> </p>
        </td>
        <td><p>Compute one-step-ahead predictive distributions for all timesteps</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="sts_sample_uniform_initial_state.html">sts_sample_uniform_initial_state()</a></code> </p>
        </td>
        <td><p>Initialize from a uniform <code>[-2, 2]</code> distribution in unconstrained space.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-generalized-linear-models" class="hasAnchor"><a href="#section-generalized-linear-models" class="anchor"></a>Generalized Linear Models</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="glm_families.html">glm_families</a></code> </p>
        </td>
        <td><p>GLM families</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="glm_fit.tensorflow.tensor.html">glm_fit(<i>&lt;tensorflow.tensor&gt;</i>)</a></code> </p>
        </td>
        <td><p>Runs multiple Fisher scoring steps</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="glm_fit_one_step.tensorflow.tensor.html">glm_fit_one_step(<i>&lt;tensorflow.tensor&gt;</i>)</a></code> </p>
        </td>
        <td><p>Runs one Fisher Scoring step</p></td>
      </tr>
    </tbody>
    </table>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Sigrid Keydana.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


