<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Marginal distribution of a Gaussian process at finitely many points. — tfd_gaussian_process • tfprobability</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Marginal distribution of a Gaussian process at finitely many points. — tfd_gaussian_process" />
<meta property="og:description" content="A Gaussian process (GP) is an indexed collection of random variables, any
finite collection of which are jointly Gaussian. While this definition applies
to finite index sets, it is typically implicit that the index set is infinite;
in applications, it is often some finite dimensional real or complex vector
space. In such cases, the GP may be thought of as a distribution over
(real- or complex-valued) functions defined over the index set." />
<meta name="twitter:card" content="summary" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tfprobability</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.8.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/dynamic_linear_models.html">Dynamic linear models</a>
    </li>
    <li>
      <a href="../articles/hamiltonian_monte_carlo.html">Multi-level modeling with Hamiltonian Monte Carlo</a>
    </li>
    <li>
      <a href="../articles/layer_dense_variational.html">Uncertainty estimates with layer_dense_variational</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/rstudio/tfprobability">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Marginal distribution of a Gaussian process at finitely many points.</h1>
    <small class="dont-index">Source: <a href='https://github.com/rstudio/tfprobability/blob/master/R/distributions.R'><code>R/distributions.R</code></a></small>
    <div class="hidden name"><code>tfd_gaussian_process.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>A Gaussian process (GP) is an indexed collection of random variables, any
finite collection of which are jointly Gaussian. While this definition applies
to finite index sets, it is typically implicit that the index set is infinite;
in applications, it is often some finite dimensional real or complex vector
space. In such cases, the GP may be thought of as a distribution over
(real- or complex-valued) functions defined over the index set.</p>
    </div>

    <pre class="usage"><span class='fu'>tfd_gaussian_process</span>(<span class='no'>kernel</span>, <span class='no'>index_points</span>, <span class='kw'>mean_fn</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>observation_noise_variance</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>jitter</span> <span class='kw'>=</span> <span class='fl'>1e-06</span>,
  <span class='kw'>validate_args</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>allow_nan_stats</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>name</span> <span class='kw'>=</span> <span class='st'>"GaussianProcess"</span>)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>kernel</th>
      <td><p><code>PositiveSemidefiniteKernel</code>-like instance representing the
GP's covariance function.</p></td>
    </tr>
    <tr>
      <th>index_points</th>
      <td><p><code>float</code> <code>Tensor</code> representing finite (batch of) vector(s) of
points in the index set over which the GP is defined. Shape has the
form <code>[b1, ..., bB, e1, f1, ..., fF]</code> where <code>F</code> is the number of feature
dimensions and must equal <code>kernel$feature_ndims</code> and <code>e1</code> is the number
(size) of index points in each batch (we denote it <code>e1</code> to distinguish
it from the numer of inducing index points, denoted <code>e2</code> below).
Ultimately the GaussianProcess distribution corresponds to an
<code>e1</code>-dimensional multivariate normal. The batch shape must be
broadcastable with <code>kernel$batch_shape</code>, the batch shape of
<code>inducing_index_points</code>, and any batch dims yielded by <code>mean_fn</code>.</p></td>
    </tr>
    <tr>
      <th>mean_fn</th>
      <td><p>function that acts on index points to produce a (batch
of) vector(s) of mean values at those index points. Takes a <code>Tensor</code> of
shape <code>[b1, ..., bB, f1, ..., fF]</code> and returns a <code>Tensor</code> whose shape is
(broadcastable with) <code>[b1, ..., bB]</code>. Default value: <code>NULL</code> implies constant zero function.</p></td>
    </tr>
    <tr>
      <th>observation_noise_variance</th>
      <td><p><code>float</code> <code>Tensor</code> representing the variance
of the noise in the Normal likelihood distribution of the model. May be
batched, in which case the batch shape must be broadcastable with the
shapes of all other batched parameters (<code>kernel$batch_shape</code>, <code>index_points</code>, etc.).
Default value: <code>0.</code></p></td>
    </tr>
    <tr>
      <th>jitter</th>
      <td><p><code>float</code> scalar <code>Tensor</code> added to the diagonal of the covariance
matrix to ensure positive definiteness of the covariance matrix. Default value: <code>1e-6</code>.</p></td>
    </tr>
    <tr>
      <th>validate_args</th>
      <td><p>Logical, default FALSE. When TRUE distribution parameters are checked
for validity despite possibly degrading runtime performance. When FALSE invalid inputs may
silently render incorrect outputs. Default value: FALSE.</p></td>
    </tr>
    <tr>
      <th>allow_nan_stats</th>
      <td><p>Logical, default TRUE. When TRUE, statistics (e.g., mean, mode, variance)
use the value NaN to indicate the result is undefined. When FALSE, an exception is raised if
one or more of the statistic's batch members are undefined.</p></td>
    </tr>
    <tr>
      <th>name</th>
      <td><p>name prefixed to Ops created by this class.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Just as Gaussian distributions are fully specified by their first and second
moments, a Gaussian process can be completely specified by a mean and
covariance function.
Let <code>S</code> denote the index set and <code>K</code> the space in which
each indexed random variable takes its values (again, often R or C). The mean
function is then a map <code>m: S -&gt; K</code>, and the covariance function, or kernel, is
a positive-definite function <code>k: (S x S) -&gt; K</code>. The properties of functions
drawn from a GP are entirely dictated (up to translation) by the form of the
kernel function.</p>
<p>This <code>Distribution</code> represents the marginal joint distribution over function
values at a given finite collection of points <code>[x[1], ..., x[N]]</code> from the
index set <code>S</code>. By definition, this marginal distribution is just a
multivariate normal distribution, whose mean is given by the vector
<code>[ m(x[1]), ..., m(x[N]) ]</code> and whose covariance matrix is constructed from
pairwise applications of the kernel function to the given inputs:</p><pre>| k(x[1], x[1])    k(x[1], x[2])  ...  k(x[1], x[N]) |
| k(x[2], x[1])    k(x[2], x[2])  ...  k(x[2], x[N]) |
|      ...              ...                 ...      |
| k(x[N], x[1])    k(x[N], x[2])  ...  k(x[N], x[N]) |
</pre>

<p>For this to be a valid covariance matrix, it must be symmetric and positive
definite; hence the requirement that <code>k</code> be a positive definite function
(which, by definition, says that the above procedure will yield PD matrices).</p>
<p>We also support the inclusion of zero-mean Gaussian noise in the model, via
the <code>observation_noise_variance</code> parameter. This augments the generative model
to</p><pre>f ~ GP(m, k)
(y[i] | f, x[i]) ~ Normal(f(x[i]), s)
</pre>

<p>where</p><ul>
<li><p><code>m</code> is the mean function</p></li>
<li><p><code>k</code> is the covariance kernel function</p></li>
<li><p><code>f</code> is the function drawn from the GP</p></li>
<li><p><code>x[i]</code> are the index points at which the function is observed</p></li>
<li><p><code>y[i]</code> are the observed values at the index points</p></li>
<li><p><code>s</code> is the scale of the observation noise.</p></li>
</ul>

<p>Note that this class represents an <em>unconditional</em> Gaussian process; it does
not implement posterior inference conditional on observed function
evaluations. This class is useful, for example, if one wishes to combine a GP
prior with a non-conjugate likelihood using MCMC to sample from the posterior.</p>
<p>Mathematical Details</p>
<p>The probability density function (pdf) is a multivariate normal whose
parameters are derived from the GP's properties:</p><pre>pdf(x; index_points, mean_fn, kernel) = exp(-0.5 * y) / Z
K = (kernel.matrix(index_points, index_points) +
    (observation_noise_variance + jitter) * eye(N))
y = (x - mean_fn(index_points))^T @ K @ (x - mean_fn(index_points))
Z = (2 * pi)**(.5 * N) |det(K)|**(.5)
</pre>

<p>where:</p><ul>
<li><p><code>index_points</code> are points in the index set over which the GP is defined,</p></li>
<li><p><code>mean_fn</code> is a callable mapping the index set to the GP's mean values,</p></li>
<li><p><code>kernel</code> is <code>PositiveSemidefiniteKernel</code>-like and represents the covariance
function of the GP,</p></li>
<li><p><code>observation_noise_variance</code> represents (optional) observation noise.</p></li>
<li><p><code>jitter</code> is added to the diagonal to ensure positive definiteness up to
machine precision (otherwise Cholesky-decomposition is prone to failure),</p></li>
<li><p><code>eye(N)</code> is an N-by-N identity matrix.</p></li>
</ul>

    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>For usage examples see e.g. <code><a href='tfd_sample.html'>tfd_sample()</a></code>, <code><a href='tfd_log_prob.html'>tfd_log_prob()</a></code>, <code><a href='tfd_mean.html'>tfd_mean()</a></code>.</p>
<p>Other distributions: <code><a href='tfd_autoregressive.html'>tfd_autoregressive</a></code>,
  <code><a href='tfd_batch_reshape.html'>tfd_batch_reshape</a></code>,
  <code><a href='tfd_bernoulli.html'>tfd_bernoulli</a></code>, <code><a href='tfd_beta.html'>tfd_beta</a></code>,
  <code><a href='tfd_binomial.html'>tfd_binomial</a></code>,
  <code><a href='tfd_categorical.html'>tfd_categorical</a></code>, <code><a href='tfd_cauchy.html'>tfd_cauchy</a></code>,
  <code><a href='tfd_chi2.html'>tfd_chi2</a></code>, <code><a href='tfd_chi.html'>tfd_chi</a></code>,
  <code><a href='tfd_cholesky_lkj.html'>tfd_cholesky_lkj</a></code>,
  <code><a href='tfd_deterministic.html'>tfd_deterministic</a></code>,
  <code><a href='tfd_dirichlet_multinomial.html'>tfd_dirichlet_multinomial</a></code>,
  <code><a href='tfd_dirichlet.html'>tfd_dirichlet</a></code>, <code><a href='tfd_empirical.html'>tfd_empirical</a></code>,
  <code><a href='tfd_exponential.html'>tfd_exponential</a></code>,
  <code><a href='tfd_gamma_gamma.html'>tfd_gamma_gamma</a></code>, <code><a href='tfd_gamma.html'>tfd_gamma</a></code>,
  <code><a href='tfd_gaussian_process_regression_model.html'>tfd_gaussian_process_regression_model</a></code>,
  <code><a href='tfd_geometric.html'>tfd_geometric</a></code>, <code><a href='tfd_gumbel.html'>tfd_gumbel</a></code>,
  <code><a href='tfd_half_cauchy.html'>tfd_half_cauchy</a></code>,
  <code><a href='tfd_half_normal.html'>tfd_half_normal</a></code>,
  <code><a href='tfd_hidden_markov_model.html'>tfd_hidden_markov_model</a></code>,
  <code><a href='tfd_horseshoe.html'>tfd_horseshoe</a></code>,
  <code><a href='tfd_independent.html'>tfd_independent</a></code>,
  <code><a href='tfd_inverse_gamma.html'>tfd_inverse_gamma</a></code>,
  <code><a href='tfd_inverse_gaussian.html'>tfd_inverse_gaussian</a></code>,
  <code><a href='tfd_joint_distribution_named.html'>tfd_joint_distribution_named</a></code>,
  <code><a href='tfd_joint_distribution_sequential.html'>tfd_joint_distribution_sequential</a></code>,
  <code><a href='tfd_kumaraswamy.html'>tfd_kumaraswamy</a></code>, <code><a href='tfd_laplace.html'>tfd_laplace</a></code>,
  <code><a href='tfd_linear_gaussian_state_space_model.html'>tfd_linear_gaussian_state_space_model</a></code>,
  <code><a href='tfd_lkj.html'>tfd_lkj</a></code>, <code><a href='tfd_log_normal.html'>tfd_log_normal</a></code>,
  <code><a href='tfd_logistic.html'>tfd_logistic</a></code>,
  <code><a href='tfd_mixture_same_family.html'>tfd_mixture_same_family</a></code>,
  <code><a href='tfd_mixture.html'>tfd_mixture</a></code>, <code><a href='tfd_multinomial.html'>tfd_multinomial</a></code>,
  <code><a href='tfd_multivariate_normal_diag_plus_low_rank.html'>tfd_multivariate_normal_diag_plus_low_rank</a></code>,
  <code><a href='tfd_multivariate_normal_diag.html'>tfd_multivariate_normal_diag</a></code>,
  <code><a href='tfd_multivariate_normal_full_covariance.html'>tfd_multivariate_normal_full_covariance</a></code>,
  <code><a href='tfd_multivariate_normal_linear_operator.html'>tfd_multivariate_normal_linear_operator</a></code>,
  <code><a href='tfd_multivariate_normal_tri_l.html'>tfd_multivariate_normal_tri_l</a></code>,
  <code><a href='tfd_multivariate_student_t_linear_operator.html'>tfd_multivariate_student_t_linear_operator</a></code>,
  <code><a href='tfd_negative_binomial.html'>tfd_negative_binomial</a></code>,
  <code><a href='tfd_normal.html'>tfd_normal</a></code>,
  <code><a href='tfd_one_hot_categorical.html'>tfd_one_hot_categorical</a></code>,
  <code><a href='tfd_pareto.html'>tfd_pareto</a></code>,
  <code><a href='tfd_poisson_log_normal_quadrature_compound.html'>tfd_poisson_log_normal_quadrature_compound</a></code>,
  <code><a href='tfd_poisson.html'>tfd_poisson</a></code>, <code><a href='tfd_quantized.html'>tfd_quantized</a></code>,
  <code><a href='tfd_relaxed_bernoulli.html'>tfd_relaxed_bernoulli</a></code>,
  <code><a href='tfd_relaxed_one_hot_categorical.html'>tfd_relaxed_one_hot_categorical</a></code>,
  <code><a href='tfd_sample_distribution.html'>tfd_sample_distribution</a></code>,
  <code><a href='tfd_sinh_arcsinh.html'>tfd_sinh_arcsinh</a></code>,
  <code><a href='tfd_student_t_process.html'>tfd_student_t_process</a></code>,
  <code><a href='tfd_student_t.html'>tfd_student_t</a></code>,
  <code><a href='tfd_transformed_distribution.html'>tfd_transformed_distribution</a></code>,
  <code><a href='tfd_triangular.html'>tfd_triangular</a></code>,
  <code><a href='tfd_truncated_normal.html'>tfd_truncated_normal</a></code>,
  <code><a href='tfd_uniform.html'>tfd_uniform</a></code>,
  <code><a href='tfd_variational_gaussian_process.html'>tfd_variational_gaussian_process</a></code>,
  <code><a href='tfd_vector_diffeomixture.html'>tfd_vector_diffeomixture</a></code>,
  <code><a href='tfd_vector_exponential_diag.html'>tfd_vector_exponential_diag</a></code>,
  <code><a href='tfd_vector_exponential_linear_operator.html'>tfd_vector_exponential_linear_operator</a></code>,
  <code><a href='tfd_vector_laplace_diag.html'>tfd_vector_laplace_diag</a></code>,
  <code><a href='tfd_vector_laplace_linear_operator.html'>tfd_vector_laplace_linear_operator</a></code>,
  <code><a href='tfd_vector_sinh_arcsinh_diag.html'>tfd_vector_sinh_arcsinh_diag</a></code>,
  <code><a href='tfd_von_mises_fisher.html'>tfd_von_mises_fisher</a></code>,
  <code><a href='tfd_von_mises.html'>tfd_von_mises</a></code>, <code><a href='tfd_wishart.html'>tfd_wishart</a></code>,
  <code><a href='tfd_zipf.html'>tfd_zipf</a></code></p></div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      <li><a href="#details">Details</a></li>
      <li><a href="#see-also">See also</a></li>
    </ul>

  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Sigrid Keydana.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


